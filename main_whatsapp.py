"""
Chatbot WhatsApp - Vicerrectorado de Investigaci√≥n UNA Puno
Versi√≥n adaptada para API de WhatsApp (sin Twilio)
Sistema dual de IA con Ollama (deepseek-v3.1:671b-cloud + gemma3:1b)
"""

import os
import json
import logging
from datetime import datetime
from collections import defaultdict
import requests
from dotenv import load_dotenv
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

# ‚≠ê IMPORTAR CLIENTE DE WHATSAPP
from whatsapp_client import WhatsAppAPIClient, extract_phone_number

# Configuraci√≥n
load_dotenv()
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Variables de entorno
OLLAMA_URL = os.getenv('OLLAMA_URL', 'http://localhost:11434')
OLLAMA_MODEL = os.getenv('OLLAMA_MODEL', 'deepseek-v3.1:671b-cloud')
OLLAMA_MODEL_BACKUP = os.getenv('OLLAMA_MODEL_BACKUP', 'gemma3:1b')

# ‚≠ê NUEVAS VARIABLES PARA LA API DE WHATSAPP
WHATSAPP_API_URL = os.getenv('WHATSAPP_API_URL', 'http://localhost:3000')
WHATSAPP_API_KEY = os.getenv('WHATSAPP_API_KEY', '@12345lin')

# Memoria conversacional
user_conversations = defaultdict(list)
MAX_HISTORY = 5

# Modelo de embeddings
embedding_model = None
faiss_index = None
documents = []

# ‚≠ê CLIENTE DE WHATSAPP (REEMPLAZA TWILIO)
whatsapp_client = None

# Expansi√≥n de t√©rminos para b√∫squeda mejorada
TERM_EXPANSION = {
    'email': ['correo', 'mail', 'correo electr√≥nico', 'correo electronico'],
    'correo': ['email', 'mail', 'correo electr√≥nico', 'correo electronico'],
    'mail': ['email', 'correo', 'correo electr√≥nico'],
    'tel√©fono': ['celular', 'telefono', 'n√∫mero', 'contacto', 'fono'],
    'celular': ['tel√©fono', 'telefono', 'n√∫mero', 'contacto', 'fono'],
    'telefono': ['celular', 'tel√©fono', 'n√∫mero', 'contacto', 'fono'],
    'n√∫mero': ['tel√©fono', 'telefono', 'celular', 'contacto'],
    'contacto': ['tel√©fono', 'telefono', 'celular', 'email', 'correo'],
    'horario': ['hora', 'horarios', 'atenci√≥n', 'atencion'],
    'ubicaci√≥n': ['ubicacion', 'lugar', 'donde', 'direcci√≥n', 'direccion', 'oficina'],
    'estad√≠stica': ['estadistica', 'estad√≠sticas', 'estadisticas', 'FIEI', 'inform√°tica', 'informatica'],
    'inform√°tica': ['informatica', 'estad√≠stica', 'estadistica', 'FIEI', 'sistemas'],
    'ingenier√≠a': ['ingenieria', 'facultad', 'escuela'],
    'agrarias': ['agronom√≠a', 'agronomia', 'agron√≥mica', 'agronomica', 'FCA'],
    'veterinaria': ['zootecnia', 'FMVZ'],
    'econ√≥mica': ['economica', 'econom√≠a', 'economia', 'FIE'],
    'contables': ['contabilidad', 'administrativas', 'administraci√≥n', 'FCCA'],
    'civil': ['arquitectura', 'FICA'],
    'minas': ['miner√≠a', 'mineria', 'FIM'],
    'qu√≠mica': ['quimica', 'FIQ'],
    'medicina': ['salud', 'FMH'],
}


def load_knowledge_base():
    """Cargar base de conocimiento FAISS"""
    global embedding_model, faiss_index, documents
    
    try:
        logger.info("Cargando modelo de embeddings...")
        embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        
        logger.info("Cargando √≠ndice FAISS...")
        faiss_index = faiss.read_index('knowledge_base.index')
        
        logger.info("Cargando documentos...")
        with open('knowledge_base.json', 'r', encoding='utf-8') as f:
            documents = json.load(f)
        
        logger.info(f"‚úì Base de conocimiento cargada: {len(documents)} documentos")
        return True
    except Exception as e:
        logger.error(f"Error cargando base de conocimiento: {e}")
        return False


def expand_query(query):
    """Expandir t√©rminos de b√∫squeda"""
    expanded_terms = [query.lower()]
    
    for word in query.lower().split():
        if word in TERM_EXPANSION:
            expanded_terms.extend(TERM_EXPANSION[word])
    
    return ' '.join(expanded_terms)


def search_knowledge_base(query, top_k=5, threshold=9.0):
    """B√∫squeda sem√°ntica mejorada en FAISS"""
    if not embedding_model or not faiss_index:
        logger.warning("Base de conocimiento no cargada")
        return []
    
    try:
        expanded_query = expand_query(query)
        logger.info(f"Query expandida: {expanded_query}")
        
        query_vector = embedding_model.encode([expanded_query])
        query_vector = np.array(query_vector).astype('float32')
        
        distances, indices = faiss_index.search(query_vector, top_k)
        
        logger.info("=== RESULTADOS DE B√öSQUEDA ===")
        for dist, idx in zip(distances[0], indices[0]):
            if idx < len(documents):
                logger.info(f"  Distancia: {dist:.3f} | {documents[idx]['title'][:60]}")
        
        results = []
        for dist, idx in zip(distances[0], indices[0]):
            if idx < len(documents):
                doc = documents[idx].copy()
                doc['distance'] = float(dist)
                
                if len(results) < 3 or dist < threshold:
                    results.append(doc)
                    logger.info(f"  ‚Üí ACEPTADO: {doc['title'][:50]}... (distancia: {dist:.3f})")
        
        logger.info(f"Resultados filtrados: {len(results)}/{top_k}")
        return results
        
    except Exception as e:
        logger.error(f"Error en b√∫squeda: {e}")
        return []


def call_ollama(prompt, model_name, stream=True):
    """Llamar a Ollama con streaming"""
    try:
        url = f"{OLLAMA_URL}/api/generate"
        payload = {
            "model": model_name,
            "prompt": prompt,
            "stream": stream,
            "options": {
                "temperature": 0.7,
                "num_predict": 450,
                "top_p": 0.85,
                "top_k": 5,
                "num_ctx": 3072,
                "repeat_penalty": 1.2
            }
        }
        
        response = requests.post(url, json=payload, stream=stream, timeout=60)
        response.raise_for_status()
        
        if stream:
            full_response = ""
            for line in response.iter_lines():
                if line:
                    data = json.loads(line)
                    if 'response' in data:
                        full_response += data['response']
                    if data.get('done', False):
                        break
            return full_response.strip()
        else:
            return response.json().get('response', '').strip()
            
    except Exception as e:
        logger.error(f"Error llamando a {model_name}: {e}")
        return None


def generate_response_dual(user_message, context="", history=""):
    """Sistema dual de IA: deepseek principal, gemma3 respaldo"""
    
    system_prompt = """Eres el asistente virtual del Vicerrectorado de Investigaci√≥n de la Universidad Nacional del Altiplano (UNA Puno). Combinas profesionalismo con calidez humana.

TU PROP√ìSITO:
Ayudar con informaci√≥n del Vicerrectorado de Investigaci√≥n:
üìß Contactos (emails y tel√©fonos)
üïê Horarios de atenci√≥n  
üìç Ubicaciones
üìö Coordinaci√≥n de investigaci√≥n y tesis
informmacion sobre resoluciones directorales

PERSONALIDAD Y ESTILO:
- Profesional pero cercano - como un buen funcionario universitario
- Usas emojis estrat√©gicamente para dar calidez (2-3 por mensaje)
- Eres claro, directo y √∫til
- Muestras empat√≠a y disposici√≥n a ayudar
- Ofreces informaci√≥n completa pero concisa

TU FORMA DE COMUNICAR:

‚úÖ BIEN:
- "Con gusto üòä, el correo de..."
- "¬°Claro! üìß Te comparto la informaci√≥n..."
- "Por supuesto, aqu√≠ est√° üìù..."
- "Entiendo que necesitas... aqu√≠ est√° üëç"
- "Perfecto, d√©jame ayudarte con eso üìã"

‚ùå EVITA:
- "Seg√∫n consta en el documento..."
- "La base de datos indica..."
- Respuestas de una sola l√≠nea sin contexto
- Ser demasiado formal o fr√≠o

MANEJO DE CONSULTAS FUERA DE ALCANCE:
Si preguntan sobre clima, hora, chistes, noticias, matem√°ticas:
"Disculpa üòä, mi especialidad es la informaci√≥n del Vicerrectorado de Investigaci√≥n. ¬øPuedo ayudarte con alg√∫n contacto de facultad, horario o ubicaci√≥n? üìö"

ESTRUCTURA DE RESPUESTA IDEAL:
1. Saludo breve o confirmaci√≥n amable
2. Informaci√≥n solicitada (espec√≠fica y completa)
3. Ofrecimiento de ayuda adicional

EJEMPLOS MODELO:

Usuario: "correo de ingenier√≠a civil"
T√∫: "¬°Por supuesto! üìß El correo de la Facultad de Ingenier√≠a Civil y Arquitectura es hyanarico@unap.edu.pe. Tambi√©n te comparto que atienden de 8:00 a 14:30 h. ¬øNecesitas el tel√©fono o la ubicaci√≥n? üòä"

Usuario: "tel√©fono de veterinaria"  
T√∫: "Con gusto üìû El tel√©fono de Medicina Veterinaria y Zootecnia es 951644391. Atienden de lunes a viernes de 8:00 a 13:00 h. ¬øTe ayudo con algo m√°s?"

Usuario: "donde esta agrarias"
T√∫: "¬°Claro! üìç La Facultad de Ciencias Agrarias est√° en el pabell√≥n antiguo de Ing. Agron√≥mica, segundo piso, oficina 206, Ciudad Universitaria. Si necesitas contactarlos: üìß fca.ui@unap.edu.pe o üìû 962382228 üòä"

REGLAS FUNDAMENTALES:
- M√°ximo 120 palabras por respuesta
- Usa informaci√≥n del contexto proporcionado directamente
- NO inventes datos que no est√©n en el contexto
- NO mezcles informaci√≥n de diferentes facultades
- Siempre cierra ofreciendo m√°s ayuda
- S√© espec√≠fico: menciona n√∫meros, ubicaciones completas, horarios exactos"""

    if context:
        full_prompt = f"""{system_prompt}

INFORMACI√ìN DISPONIBLE:
{context}

{"CONVERSACI√ìN PREVIA:\n" + history if history else ""}

PREGUNTA DEL USUARIO: {user_message}

RESPUESTA (m√°ximo 150 palabras):"""
    else:
        full_prompt = f"""{system_prompt}

{"CONVERSACI√ìN PREVIA:\n" + history if history else ""}

PREGUNTA DEL USUARIO: {user_message}

RESPUESTA (m√°ximo 150 palabras):"""

    logger.info(f"Intentando con {OLLAMA_MODEL}...")
    response = call_ollama(full_prompt, OLLAMA_MODEL)
    
    if response:
        logger.info(f"‚úì Respuesta de {OLLAMA_MODEL}")
        return response, OLLAMA_MODEL
    
    logger.warning(f"{OLLAMA_MODEL} fall√≥, usando {OLLAMA_MODEL_BACKUP}...")
    response = call_ollama(full_prompt, OLLAMA_MODEL_BACKUP)
    
    if response:
        logger.info(f"‚úì Respuesta de {OLLAMA_MODEL_BACKUP}")
        return response, OLLAMA_MODEL_BACKUP
    
    return "Lo siento, tengo problemas t√©cnicos. Por favor, intenta de nuevo.", "error"


def get_conversation_history(phone_number):
    """Obtener historial de conversaci√≥n"""
    history = user_conversations[phone_number]
    if not history:
        return ""
    
    formatted = []
    for entry in history[-MAX_HISTORY:]:
        formatted.append(f"Usuario: {entry['user']}")
        formatted.append(f"Asistente: {entry['bot']}")
    
    return "\n".join(formatted)


def add_to_history(phone_number, user_msg, bot_msg):
    """Agregar interacci√≥n al historial"""
    user_conversations[phone_number].append({
        'user': user_msg,
        'bot': bot_msg,
        'timestamp': datetime.now().isoformat()
    })
    
    if len(user_conversations[phone_number]) > MAX_HISTORY:
        user_conversations[phone_number] = user_conversations[phone_number][-MAX_HISTORY:]
    
    save_stats_to_file()


def process_message(user_message, phone_number):
    """Procesar mensaje del usuario"""
    user_message = user_message.strip()
    
    # Comandos especiales
    if user_message.lower() == '/reset':
        user_conversations[phone_number] = []
        return "‚úì Conversaci√≥n reiniciada. ¬øEn qu√© puedo ayudarte?"
    
    if user_message.lower() in ['/ayuda', '/help']:
        return """Comandos disponibles:
/reset - Reiniciar conversaci√≥n
/ayuda - Mostrar esta ayuda

Puedo ayudarte con informaci√≥n sobre:
- Coordinadores de facultades
- Correos y tel√©fonos
- Horarios de atenci√≥n
- Ubicaciones

¬øQu√© necesitas saber?"""
    
    # Filtro de preguntas triviales
    trivial_keywords = [
        'hora', 'fecha', 'd√≠a', 'clima', 'tiempo', 'chiste', 
        'partido', 'f√∫tbol', 'matem√°tica', 'calcula'
    ]
    
    user_lower = user_message.lower()
    if any(keyword in user_lower for keyword in trivial_keywords):
        uni_keywords = ['universidad', 'facultad', 'coordinador', 'email', 'correo']
        if not any(uni_word in user_lower for uni_word in uni_keywords):
            return "Lo siento, solo puedo ayudarte con informaci√≥n del Vicerrectorado de Investigaci√≥n."
    
    # Saludo
    if user_message.lower() in ['hola', 'hi', 'hello', 'buenos d√≠as', 'buenas tardes']:
        return "¬°Hola! Soy el asistente virtual del Vicerrectorado de Investigaci√≥n de la UNA Puno. ¬øEn qu√© puedo ayudarte?"
    
    # B√∫squeda en base de conocimiento
    logger.info(f"Procesando: '{user_message}' de {phone_number}")
    relevant_docs = search_knowledge_base(user_message, top_k=10, threshold=9.0)
    
    context = ""
    if relevant_docs:
        context = "\n\n".join([doc['content'] for doc in relevant_docs])
        logger.info(f"Contexto encontrado: {len(context)} caracteres")
    
    history = get_conversation_history(phone_number)
    response, model_used = generate_response_dual(user_message, context, history)
    
    # Limitar a 1600 caracteres (l√≠mite WhatsApp)
    if len(response) > 1600:
        response = response[:1597] + "..."
    
    add_to_history(phone_number, user_message, response)
    
    logger.info(f"Respuesta enviada (modelo: {model_used}): {len(response)} caracteres")
    return response


def save_stats_to_file():
    """Guardar estad√≠sticas en archivo JSON"""
    try:
        stats = {
            'timestamp': datetime.now().isoformat(),
            'total_users': len(user_conversations),
            'total_messages': sum(len(convs) for convs in user_conversations.values()),
            'kb_documents': len(documents),
            'model_used': OLLAMA_MODEL.split(':')[0] if ':' in OLLAMA_MODEL else OLLAMA_MODEL,
            'conversations': []
        }
        
        for phone, convs in user_conversations.items():
            for conv in convs:
                stats['conversations'].append({
                    'phone': phone,
                    'timestamp': conv['timestamp'],
                    'user': conv['user'],
                    'bot': conv['bot']
                })
        
        with open('dashboard_stats.json', 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        logger.error(f"Error guardando estad√≠sticas: {e}")


# ‚≠ê NUEVA FUNCI√ìN: Manejador de mensajes de WhatsApp
def handle_incoming_message(message):
    """
    Callback para procesar mensajes entrantes desde la API
    
    Args:
        message: Dict con datos del mensaje de la API
    """
    try:
        # Extraer datos del mensaje
        phone_number = extract_phone_number(message)
        user_message = message.get('body', '').strip()
        
        logger.info(f"üì® Mensaje de {phone_number}: {user_message}")
        
        # Procesar con la l√≥gica del chatbot
        bot_response = process_message(user_message, phone_number)
        
        # Enviar respuesta usando la API de WhatsApp
        success = whatsapp_client.send_text(phone_number, bot_response)
        
        if success:
            logger.info(f"‚úÖ Respuesta enviada a {phone_number}")
        else:
            logger.error(f"‚ùå Error enviando respuesta a {phone_number}")
            
    except Exception as e:
        logger.error(f"Error manejando mensaje: {e}", exc_info=True)

async def send_media_url(self, phone: str, media_url: str, caption: str = "") -> bool:
    """Enviar archivo por URL"""
    try:
        headers = {
            'x-api-key': self.api_key,
            'Content-Type': 'application/json'
        }
        
        url = f"{self.api_url}/api/whatsapp/send/media-url"
        
        payload = {
            'phone': phone,
            'mediaUrl': media_url,
            'caption': caption
        }
        
        async with self.session.post(url, headers=headers, json=payload, timeout=30) as resp:
            success = resp.status == 200
            if success:
                logger.info(f"‚úÖ Archivo enviado a {phone}")
            else:
                logger.error(f"‚ùå Error enviando archivo: {resp.status}")
            return success
    
    except Exception as e:
        logger.error(f"Error en send_media_url: {e}")
        return False

if __name__ == '__main__':
    logger.info("=" * 60)
    logger.info("CHATBOT WHATSAPP - VICERRECTORADO DE INVESTIGACI√ìN UNA PUNO")
    logger.info("Versi√≥n con API de WhatsApp (sin Twilio)")
    logger.info("=" * 60)
    
    # Cargar base de conocimiento
    if not load_knowledge_base():
        logger.error("¬°ERROR! No se pudo cargar la base de conocimiento")
        logger.error("Ejecuta primero: python ingest.py")
        exit(1)
    
    # Inicializar estad√≠sticas
    logger.info("Inicializando archivo de estad√≠sticas...")
    save_stats_to_file()
    
    # ‚≠ê CREAR CLIENTE DE WHATSAPP (REEMPLAZA TWILIO)
    logger.info(f"\nüì± Conectando a API de WhatsApp...")
    logger.info(f"   URL: {WHATSAPP_API_URL}")
    
    whatsapp_client = WhatsAppAPIClient(WHATSAPP_API_URL, WHATSAPP_API_KEY)
    
    # Verificar conexi√≥n
    if not whatsapp_client.check_connection():
        logger.error("\n‚ùå ERROR: No se puede conectar a la API de WhatsApp")
        logger.error("   Aseg√∫rate de que:")
        logger.error("   1. La API est√© corriendo: npm run dev")
        logger.error("   2. WhatsApp est√© autenticado y conectado")
        logger.error(f"   3. WHATSAPP_API_URL={WHATSAPP_API_URL}")
        logger.error(f"   4. WHATSAPP_API_KEY={WHATSAPP_API_KEY}")
        exit(1)
    
    logger.info("‚úÖ Conectado a API de WhatsApp")
    logger.info(f"\nModelo principal: {OLLAMA_MODEL}")
    logger.info(f"Modelo respaldo: {OLLAMA_MODEL_BACKUP}")
    logger.info("=" * 60)
    logger.info("\nü§ñ Chatbot iniciado. Esperando mensajes...")
    logger.info("   Presiona Ctrl+C para detener\n")
    
    # ‚≠ê INICIAR POLLING (REEMPLAZA WEBHOOK DE FLASK)
    whatsapp_client.start_polling(handle_incoming_message, interval=2)